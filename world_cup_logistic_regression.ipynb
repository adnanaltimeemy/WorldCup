{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca43801",
   "metadata": {},
   "source": [
    "\n",
    "# Logistic Regression — World Cup Matches\n",
    "This notebook trains a **logistic regression** model to predict whether the **home team wins** a match using multiple features from the dataset.\n",
    "\n",
    "**Workflow**\n",
    "1. Load & inspect data  \n",
    "2. Feature engineering (binary target `home_win`, `is_knockout`, cleaned `attendance`)  \n",
    "3. Train/test split  \n",
    "4. Pipeline: Imputation + Scaling + One-Hot + **LogisticRegression**  \n",
    "5. Evaluation: Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC, Confusion Matrix  \n",
    "6. Coefficients & Odds Ratios (feature effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, average_precision_score, precision_recall_curve,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Load data\n",
    "csv_path = \"/mnt/data/WorldCupMatches_cleaned.csv\"\n",
    "df_raw = pd.read_csv(csv_path)\n",
    "df_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d757ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick structure and missingness\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "print(\"\\nColumns:\", list(df_raw.columns))\n",
    "print(\"\\nNull counts:\\n\", df_raw.isna().sum())\n",
    "df_raw.describe(include='all').T.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b8f007",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cafc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d.columns = [c.lower() for c in d.columns]\n",
    "\n",
    "    # Target: home team win (1) vs not win (0)\n",
    "    if {\"home_team_goals\", \"away_team_goals\"}.issubset(set(d.columns)):\n",
    "        d[\"home_win\"] = (pd.to_numeric(d[\"home_team_goals\"], errors=\"coerce\") >\n",
    "                         pd.to_numeric(d[\"away_team_goals\"], errors=\"coerce\")).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset must include 'home_team_goals' and 'away_team_goals'.\")\n",
    "\n",
    "    # Attendance cleanup\n",
    "    if \"attendance\" in d.columns:\n",
    "        d[\"attendance\"] = (\n",
    "            d[\"attendance\"].astype(str)\n",
    "            .str.replace(\",\", \"\", regex=False)\n",
    "            .str.extract(r\"(\\d+)\", expand=False)\n",
    "        )\n",
    "        d[\"attendance\"] = pd.to_numeric(d[\"attendance\"], errors=\"coerce\")\n",
    "\n",
    "    # Year numeric\n",
    "    if \"year\" in d.columns:\n",
    "        d[\"year\"] = pd.to_numeric(d[\"year\"], errors=\"coerce\")\n",
    "\n",
    "    # Knockout flag derived from stage\n",
    "    if \"stage\" in d.columns:\n",
    "        d[\"is_knockout\"] = ~d[\"stage\"].astype(str).str.contains(\"group\", case=False, na=False)\n",
    "        d[\"is_knockout\"] = d[\"is_knockout\"].astype(int)\n",
    "\n",
    "    # Ensure optional numeric columns are numeric if present\n",
    "    for col in [\"half-time_home_goals\", \"half-time_away_goals\", \"goal_difference\"]:\n",
    "        if col in d.columns:\n",
    "            d[col] = pd.to_numeric(d[col], errors=\"coerce\")\n",
    "\n",
    "    return d\n",
    "\n",
    "df = engineer_features(df_raw)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a4e12",
   "metadata": {},
   "source": [
    "## Select Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = \"home_win\"\n",
    "\n",
    "candidate_numeric = [\n",
    "    \"year\", \"attendance\", \"is_knockout\",\n",
    "    \"half-time_home_goals\", \"half-time_away_goals\", \"goal_difference\"\n",
    "]\n",
    "numeric_features = [c for c in candidate_numeric if c in df.columns]\n",
    "\n",
    "candidate_categorical = [\"stage\", \"city\", \"stadium\", \"referee\"]\n",
    "categorical_features = [c for c in candidate_categorical if c in df.columns]\n",
    "\n",
    "feature_cols = numeric_features + categorical_features\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Drop rows with missing target (should be none after casting)\n",
    "mask = df[target].notna()\n",
    "df = df.loc[mask].copy()\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target]\n",
    "\n",
    "print(\"X shape:\", X.shape, \"y length:\", len(y), \"| Positive rate:\", float(y.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df42895",
   "metadata": {},
   "source": [
    "## Train/Test Split & Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, numeric_features),\n",
    "        (\"cat\", categorical_pipe, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "logreg = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "print({{\n",
    "    \"accuracy\": acc,\n",
    "    \"precision\": prec,\n",
    "    \"recall\": rec,\n",
    "    \"f1\": f1,\n",
    "    \"roc_auc\": roc_auc,\n",
    "    \"pr_auc\": pr_auc\n",
    "}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b0443",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_scores = cross_val_score(logreg, X, y, cv=min(5, len(y)), scoring=\"accuracy\")\n",
    "print(\"CV accuracy:\", cv_scores, \"mean =\", float(np.mean(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204277b",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb466d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Home Win — Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Precision-Recall curve\n",
    "precisions, recalls, _ = precision_recall_curve(y_test, y_proba)\n",
    "plt.figure()\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b177c",
   "metadata": {},
   "source": [
    "## Coefficients & Odds Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get feature names post-encoding\n",
    "ohe = None\n",
    "if len(categorical_features):\n",
    "    ohe = logreg.named_steps[\"preprocess\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "num_names = numeric_features\n",
    "cat_names = list(ohe.get_feature_names_out(categorical_features)) if ohe is not None else []\n",
    "all_feature_names = num_names + cat_names\n",
    "\n",
    "coefs = logreg.named_steps[\"clf\"].coef_[0]\n",
    "coef_df = pd.DataFrame({{\"feature\": all_feature_names, \"coef\": coefs}})\n",
    "coef_df[\"odds_ratio\"] = np.exp(coef_df[\"coef\"])\n",
    "\n",
    "# Top positive and negative effects\n",
    "coef_df.sort_values(\"coef\", ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coef_df.sort_values(\"coef\", ascending=True).head(15)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
